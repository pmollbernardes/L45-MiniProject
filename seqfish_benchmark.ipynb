{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import squidpy as sq\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics\n",
    "from scipy.sparse import hstack\n",
    "import json\n",
    "from scipy.sparse import csr_matrix, csc_matrix\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sq.datasets.seqfish()\n",
    "\n",
    "labels = adata.obs['celltype_mapped_refined'].cat.codes.values\n",
    "classes = np.unique(labels)\n",
    "_, counts = np.unique(labels, return_counts=True)\n",
    "\n",
    "X_with_spatial = csc_matrix(hstack((adata.X, adata.obsm['spatial'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(filename, results):\n",
    "    with open(f\"results/{filename}\", 'w') as f:\n",
    "        for result in results:\n",
    "            json.dump(result, f)\n",
    "            f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(y_true, y_pred):\n",
    "    return {\n",
    "        'accuracy_score': metrics.accuracy_score(y_true, y_pred),\n",
    "        'balanced_accuracy': metrics.balanced_accuracy_score(y_true, y_pred),\n",
    "        'f1_score': metrics.f1_score(y_true, y_pred, average='macro', labels=classes, zero_division=0),\n",
    "        'recall': metrics.recall_score(y_true, y_pred, average='macro', labels=classes, zero_division=0),\n",
    "        'precision_score': metrics.precision_score(y_true, y_pred, average='macro', labels=classes, zero_division=0),\n",
    "    }\n",
    "\n",
    "def average_stats(stats_list):\n",
    "    keys = stats_list[0].keys()\n",
    "    n = len(stats_list)\n",
    "    avg = {}\n",
    "    for key in keys:\n",
    "        sum = 0\n",
    "        for stats in stats_list:\n",
    "            sum += stats[key]\n",
    "        avg[key] = sum / n\n",
    "    return avg\n",
    "\n",
    "def eval_k_fold(model, x, y, x_rotated=None):\n",
    "    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=1604)\n",
    "    stats_list = []\n",
    "    for train_index, test_index in skf.split(x, y):\n",
    "        model.fit(x[train_index], y[train_index])\n",
    "        if x_rotated is None:\n",
    "            pred = model.predict(x[test_index])\n",
    "        else:\n",
    "            pred = model.predict(x_rotated[test_index])\n",
    "        stats_list.append(get_stats(y[test_index], pred))\n",
    "    avg = average_stats(stats_list)\n",
    "    print(avg)\n",
    "    return avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy_score': 0.8413679439637413, 'balanced_accuracy': 0.6828352659430069, 'f1_score': 0.6918458992784452, 'recall': 0.6828352659430069, 'precision_score': 0.7290956057127514}\n",
      "{'accuracy_score': 0.8281829419035848, 'balanced_accuracy': 0.7281286772368624, 'f1_score': 0.7290112621762397, 'recall': 0.7281286772368624, 'precision_score': 0.7323814334540106}\n",
      "{'accuracy_score': 0.6240214256283477, 'balanced_accuracy': 0.49516211234458024, 'f1_score': 0.5588964861312239, 'recall': 0.49516211234458024, 'precision_score': 0.6986243630057913}\n"
     ]
    }
   ],
   "source": [
    "for kernel in ['rbf', 'linear', 'poly']:\n",
    "    classifier = svm.SVC(kernel=kernel)\n",
    "    res = eval_k_fold(classifier, adata.X, labels)\n",
    "    res['description'] = f\"No spatial data, kernel: {kernel}\"\n",
    "    svm_results.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy_score': 0.8203543469303667, 'balanced_accuracy': 0.7471576512078603, 'f1_score': 0.7308501526615956, 'recall': 0.7471576512078603, 'precision_score': 0.7256952092760219}\n",
      "{'accuracy_score': 0.8203543469303667, 'balanced_accuracy': 0.7471576512078603, 'f1_score': 0.7308501526615956, 'recall': 0.7471576512078603, 'precision_score': 0.7256952092760219}\n",
      "{'accuracy_score': 0.8203543469303667, 'balanced_accuracy': 0.7471576512078603, 'f1_score': 0.7308501526615956, 'recall': 0.7471576512078603, 'precision_score': 0.7256952092760219}\n"
     ]
    }
   ],
   "source": [
    "for kernel in ['rbf', 'linear', 'poly']:\n",
    "    classifier = svm.SVC(kernel=kernel, class_weight='balanced')\n",
    "    res = eval_k_fold(classifier, adata.X, labels)\n",
    "    res['description'] = f\"No spatial data, balanced, kernel: {kernel}\"\n",
    "    svm_results.append(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy_score': 0.829264524103832, 'balanced_accuracy': 0.7303053199557742, 'f1_score': 0.7305527279949368, 'recall': 0.7303053199557742, 'precision_score': 0.7339299108801014}\n"
     ]
    }
   ],
   "source": [
    "classifier = svm.SVC(kernel='linear')\n",
    "res = eval_k_fold(classifier, X_with_spatial, labels)\n",
    "res['description'] = \"With spatial data\"\n",
    "svm_results.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy_score': 0.8210754017305315, 'balanced_accuracy': 0.7129611918915871, 'f1_score': 0.7156881576040005, 'recall': 0.7129611918915871, 'precision_score': 0.7259928579521387}\n"
     ]
    }
   ],
   "source": [
    "theta = math.pi / 2\n",
    "R = np.array([[math.cos(theta), -math.sin(theta)],\n",
    "             [math.sin(theta), math.cos(theta)]])\n",
    "X_with_spatial_rotated = hstack(\n",
    "    (X_with_spatial[:, :-2], X_with_spatial[:, -2:] @ csr_matrix(R)))\n",
    "pred = classifier.predict(X_with_spatial_rotated)\n",
    "res = eval_k_fold(classifier, X_with_spatial, labels,\n",
    "                  x_rotated=X_with_spatial_rotated)\n",
    "res['description'] = \"With spatial data, rotated\"\n",
    "svm_results.append(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(\"svm_results\", svm_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pedro\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\pedro\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\pedro\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy_score': 0.8352389781623404, 'balanced_accuracy': 0.7084716163352285, 'f1_score': 0.7162633856026237, 'recall': 0.7084716163352285, 'precision_score': 0.7276849431845185}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pedro\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\pedro\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy_score': 0.8292130201895344, 'balanced_accuracy': 0.726384720763188, 'f1_score': 0.7233818499279714, 'recall': 0.726384720763188, 'precision_score': 0.7229241824601855}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pedro\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logistic_results = []\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "res = eval_k_fold(classifier, adata.X, labels)\n",
    "res['description'] = \"Logistic regression, unbalanced\"\n",
    "logistic_results.append(res)\n",
    "\n",
    "classifier = LogisticRegression(class_weight='balanced')\n",
    "res = eval_k_fold(classifier, adata.X, labels)\n",
    "res['description'] = \"Logistic regression, balanced\"\n",
    "logistic_results.append(res)\n",
    "\n",
    "save_results(\"logistic_results\", logistic_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy_score': 0.8489905232797693, 'balanced_accuracy': 0.7332014135424075, 'f1_score': 0.7407069072031857, 'recall': 0.7332014135424075, 'precision_score': 0.7523453085864468}\n",
      "{'accuracy_score': 0.8489905232797693, 'balanced_accuracy': 0.7332014135424075, 'f1_score': 0.7407069072031857, 'recall': 0.7332014135424075, 'precision_score': 0.7523453085864468, 'description': 'MLP classifier, hidden layer size: (256, 256)'}\n"
     ]
    }
   ],
   "source": [
    "mlp_results = []\n",
    "hidden_layer_sizes = [(128,), (256,), (128,128,), (256,256)]\n",
    "for hidden_layer_size in hidden_layer_sizes:\n",
    "    classifier = MLPClassifier(hidden_layer_sizes=hidden_layer_size, alpha=0.0001, early_stopping=False, validation_fraction=0.1, tol=1e-4, learning_rate_init=0.001, n_iter_no_change=10)\n",
    "    res = eval_k_fold(classifier, adata.X, labels)\n",
    "    res['description'] = f\"MLP classifier, hidden layer size: {hidden_layer_size}\"\n",
    "    print(res)\n",
    "    mlp_results.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(\"mlp_results\", mlp_results)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "74ab7c6ffe6706754a8af46cc4d18eebe476c74ce21a19282f620e1b1e9919fe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
